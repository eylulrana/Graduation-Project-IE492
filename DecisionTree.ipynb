{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "# Load the data\n",
    "\n",
    "merged_df = pd.read_csv(\"cleanedData.csv\")\n",
    "\n",
    "# Filter data for April 2024 and other dates\n",
    "\n",
    "test_data_with_date = merged_df[merged_df[\"trxdate\"] == '2024-04']\n",
    "\n",
    "train_data_with_date = merged_df[merged_df[\"trxdate\"] != '2024-04']\n",
    "\n",
    "# Drop trxdate column\n",
    "\n",
    "test_data_april = test_data_with_date.drop(columns=[\"trxdate\"])\n",
    "\n",
    "train_data_april = train_data_with_date.drop(columns=[\"trxdate\"])\n",
    "\n",
    "# Separate features and target variable\n",
    "\n",
    "X = train_data_april.drop(columns=[\"Churn\"])\n",
    "\n",
    "y = train_data_april[\"Churn\"]\n",
    "\n",
    "# Function to create different scenarios and evaluate model\n",
    "\n",
    "def evaluate_model_for_ratios_and_depths(churn_ratio, max_depth):\n",
    "\n",
    "    churn_data = train_data_april[train_data_april[\"Churn\"] == 1]\n",
    "\n",
    "    non_churn_data = train_data_april[train_data_april[\"Churn\"] == 0]\n",
    "\n",
    "    # Number of non-churn samples to match the desired ratio\n",
    "\n",
    "    non_churn_sample_size = int(len(churn_data) * (1 - churn_ratio) / churn_ratio)\n",
    "\n",
    "    if non_churn_sample_size > len(non_churn_data):\n",
    "\n",
    "        non_churn_sample_size = len(non_churn_data)\n",
    "\n",
    "    non_churn_sample = non_churn_data.sample(non_churn_sample_size, random_state=42)\n",
    "\n",
    "    # Combine churn and non-churn data\n",
    "\n",
    "    balanced_data = pd.concat([churn_data, non_churn_sample])\n",
    "\n",
    "    X_balanced = balanced_data.drop(columns=[\"Churn\"])\n",
    "\n",
    "    y_balanced = balanced_data[\"Churn\"]\n",
    " \n",
    "    # Print the number of churn and non-churn samples\n",
    "\n",
    "    num_churn_samples = len(churn_data)\n",
    "\n",
    "    num_non_churn_samples = len(non_churn_sample)\n",
    "\n",
    "    print(f\"Churn Samples: {num_churn_samples}, Non-Churn Samples: {num_non_churn_samples}\")\n",
    "\n",
    "    # Split data into training and validation sets\n",
    "\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X_balanced, y_balanced, test_size=0.3, random_state=42)\n",
    "\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "    # Train Decision Tree model\n",
    "\n",
    "    model_tree = DecisionTreeClassifier(max_depth=max_depth, random_state=42)\n",
    "\n",
    "    model_tree.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate model on validation set\n",
    "\n",
    "    y_val_pred = model_tree.predict(X_val)\n",
    "\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "    val_precision = precision_score(y_val, y_val_pred)\n",
    "\n",
    "    val_recall = recall_score(y_val, y_val_pred)\n",
    "\n",
    "    val_f1 = f1_score(y_val, y_val_pred)\n",
    "\n",
    "    # Evaluate model on test set\n",
    "\n",
    "    y_test_pred = model_tree.predict(X_test)\n",
    "\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    test_precision = precision_score(y_test, y_test_pred)\n",
    "\n",
    "    test_recall = recall_score(y_test, y_test_pred)\n",
    "\n",
    "    test_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "    print(f\"Churn Ratio: {churn_ratio * 100}% | Max Depth: {max_depth}\")\n",
    "\n",
    "    print(\"Validation Metrics:\")\n",
    "\n",
    "    print(\"Accuracy:\", val_accuracy)\n",
    "\n",
    "    print(\"Precision:\", val_precision)\n",
    "\n",
    "    print(\"Recall:\", val_recall)\n",
    "\n",
    "    print(\"F1 Score:\", val_f1)\n",
    "\n",
    "    print()\n",
    "\n",
    "    print(\"Test Metrics:\")\n",
    "\n",
    "    print(\"Accuracy:\", test_accuracy)\n",
    "\n",
    "    print(\"Precision:\", test_precision)\n",
    "\n",
    "    print(\"Recall:\", test_recall)\n",
    "\n",
    "    print(\"F1 Score:\", test_f1)\n",
    "\n",
    "    print()\n",
    "\n",
    "    # Predict and evaluate on April 2024 data\n",
    "\n",
    "    test_data_april_without_churn = test_data_april.drop(columns=[\"Churn\"])\n",
    "\n",
    "    april_prediction = model_tree.predict(test_data_april_without_churn)\n",
    "\n",
    "    april_prediction_proba = model_tree.predict_proba(test_data_april_without_churn)[:, 1]\n",
    "\n",
    "    comparison_df = pd.DataFrame({\n",
    "\n",
    "        \"Customer_id\": test_data_april[\"Customer_id\"],\n",
    "\n",
    "        \"True_Churn\": test_data_april[\"Churn\"],\n",
    "\n",
    "        \"Predicted_Churn\": april_prediction,\n",
    "\n",
    "        \"Predicted_Churn_Probability\": april_prediction_proba\n",
    "\n",
    "    })\n",
    "\n",
    "    print(\"Classification Report for April 2024:\")\n",
    "\n",
    "    print(classification_report(test_data_april[\"Churn\"], april_prediction))\n",
    "\n",
    "    print(\"Confusion Matrix for April 2024:\")\n",
    "\n",
    "    print(confusion_matrix(test_data_april[\"Churn\"], april_prediction))\n",
    "\n",
    "    print()\n",
    "\n",
    "\n",
    "# Evaluate for different churn ratios and max_depth values\n",
    "\n",
    "ratios = [ 0.5, 0.4, 0.3, 0.2]\n",
    "depths = [10, 15, 20, 25, 30, 35, 40]\n",
    "\n",
    "for ratio in ratios:\n",
    "\n",
    "    for depth in depths:\n",
    "\n",
    "        evaluate_model_for_ratios_and_depths(ratio, depth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Customer_id  ChurnProbability ValueSegment\n",
      "14         97425734          0.000000           A1\n",
      "22         97425700          0.000000            B\n",
      "25         97425673          0.000000            D\n",
      "43         97425610          0.000000            C\n",
      "48         97425607          0.000000            B\n",
      "...             ...               ...          ...\n",
      "465143     18081987          0.000000            C\n",
      "465146     17906588          0.000000            C\n",
      "465150     17052005          0.145963           A2\n",
      "465161     17011971          0.000000           A1\n",
      "465165     16082019          0.420455            D\n",
      "\n",
      "[51169 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    " \n",
    "# Veriyi yükle\n",
    "merged_df = pd.read_csv(\"cleanedData.csv\")\n",
    " \n",
    "# Nisan 2024 ve diğer tarihler için veriyi filtrele\n",
    "test_data_with_date = merged_df[merged_df[\"trxdate\"] == '2024-04']\n",
    "train_data_with_date = merged_df[merged_df[\"trxdate\"] != '2024-04']\n",
    " \n",
    "# trxdate sütununu kaldır\n",
    "test_data_april = test_data_with_date.drop(columns=[\"trxdate\"])\n",
    "train_data_april = train_data_with_date.drop(columns=[\"trxdate\"])\n",
    " \n",
    "# Özellikleri ve hedef değişkeni ayır\n",
    "X = train_data_april.drop(columns=[\"Churn\"])\n",
    "y = train_data_april[\"Churn\"]\n",
    " \n",
    "# Decision Tree modelini eğit\n",
    "model_tree = DecisionTreeClassifier(max_depth=10, random_state=42)\n",
    "model_tree.fit(X, y)\n",
    " \n",
    "# Test seti üzerinde tahminler yap\n",
    "test_data_april_without_churn = test_data_april.drop(columns=[\"Churn\"])\n",
    "april_prediction_proba = model_tree.predict_proba(test_data_april_without_churn)[:, 1]\n",
    " \n",
    "# Tahminleri DataFrame'e ekle\n",
    "result_df = pd.DataFrame({\n",
    "    \"Customer_id\": test_data_april[\"Customer_id\"],\n",
    "    \"ChurnProbability\": april_prediction_proba\n",
    "})\n",
    " \n",
    "# Müşterinin hangi segmente ait olduğunu belirle\n",
    "def determine_value_segment(row):\n",
    "    for column in [\"ValueSegment_A1\", \"ValueSegment_A2\", \"ValueSegment_B\", \"ValueSegment_C\", \"ValueSegment_D\"]:\n",
    "        if row[column] == 1:\n",
    "            return column.split(\"_\")[1]\n",
    "    return None\n",
    " \n",
    "# Müşterinin hangi segmente ait olduğunu DataFrame'e ekle\n",
    "test_data_april[\"ValueSegment\"] = test_data_april.apply(determine_value_segment, axis=1)\n",
    "result_df[\"ValueSegment\"] = test_data_april[\"ValueSegment\"]\n",
    " \n",
    "# Sonuçları yazdır ve kaydet\n",
    "print(result_df)\n",
    "result_df.to_csv(\"churn_predictions_with_ValueSegment.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
