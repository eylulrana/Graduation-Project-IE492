{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Churn Ratio: 50.0%\n",
      "Validation Metrics:\n",
      "Accuracy: 0.6352014900101591\n",
      "Precision: 0.5923319582625576\n",
      "Recall: 0.8372491853884411\n",
      "F1 Score: 0.693810843459106\n",
      "\n",
      "Test Metrics:\n",
      "Accuracy: 0.6380259036654533\n",
      "Precision: 0.6014187808103884\n",
      "Recall: 0.8388395103136005\n",
      "F1 Score: 0.7005602240896358\n",
      "\n",
      "Classification Report for April 2024:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.58      0.72     45852\n",
      "           1       0.17      0.77      0.28      5317\n",
      "\n",
      "    accuracy                           0.60     51169\n",
      "   macro avg       0.57      0.67      0.50     51169\n",
      "weighted avg       0.87      0.60      0.67     51169\n",
      "\n",
      "Confusion Matrix for April 2024:\n",
      "[[26484 19368]\n",
      " [ 1218  4099]]\n",
      "\n",
      "Churn Ratio: 40.0%\n",
      "Validation Metrics:\n",
      "Accuracy: 0.6009481882831019\n",
      "Precision: 0.6386554621848739\n",
      "Recall: 0.03805708562844266\n",
      "F1 Score: 0.0718336483931947\n",
      "\n",
      "Test Metrics:\n",
      "Accuracy: 0.6099146688338074\n",
      "Precision: 0.5896656534954408\n",
      "Recall: 0.03333906169444922\n",
      "F1 Score: 0.0631099544567339\n",
      "\n",
      "Classification Report for April 2024:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94     45852\n",
      "           1       0.35      0.03      0.05      5317\n",
      "\n",
      "    accuracy                           0.89     51169\n",
      "   macro avg       0.62      0.51      0.50     51169\n",
      "weighted avg       0.84      0.89      0.85     51169\n",
      "\n",
      "Confusion Matrix for April 2024:\n",
      "[[45558   294]\n",
      " [ 5162   155]]\n",
      "\n",
      "Churn Ratio: 30.0%\n",
      "Validation Metrics:\n",
      "Accuracy: 0.7009193884289124\n",
      "Precision: 0.48\n",
      "Recall: 0.0020383896721589945\n",
      "F1 Score: 0.0040595399188092015\n",
      "\n",
      "Test Metrics:\n",
      "Accuracy: 0.6976177172753594\n",
      "Precision: 0.48484848484848486\n",
      "Recall: 0.002688172043010753\n",
      "F1 Score: 0.00534670008354219\n",
      "\n",
      "Classification Report for April 2024:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95     45852\n",
      "           1       0.45      0.00      0.01      5317\n",
      "\n",
      "    accuracy                           0.90     51169\n",
      "   macro avg       0.67      0.50      0.48     51169\n",
      "weighted avg       0.85      0.90      0.85     51169\n",
      "\n",
      "Confusion Matrix for April 2024:\n",
      "[[45825    27]\n",
      " [ 5295    22]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Churn Ratio: 20.0%\n",
      "Validation Metrics:\n",
      "Accuracy: 0.8002031832035218\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 Score: 0.0\n",
      "\n",
      "Test Metrics:\n",
      "Accuracy: 0.8010903796010972\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 Score: 0.0\n",
      "\n",
      "Classification Report for April 2024:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95     45852\n",
      "           1       0.00      0.00      0.00      5317\n",
      "\n",
      "    accuracy                           0.90     51169\n",
      "   macro avg       0.45      0.50      0.47     51169\n",
      "weighted avg       0.80      0.90      0.85     51169\n",
      "\n",
      "Confusion Matrix for April 2024:\n",
      "[[45852     0]\n",
      " [ 5317     0]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    " \n",
    "# Load the data\n",
    "merged_df = pd.read_csv(\"cleanedData.csv\")\n",
    " \n",
    "# Filter data for April 2024 and other dates\n",
    "test_data_with_date = merged_df[merged_df[\"trxdate\"] == '2024-04']\n",
    "train_data_with_date = merged_df[merged_df[\"trxdate\"] != '2024-04']\n",
    " \n",
    "# Drop trxdate column\n",
    "test_data_april = test_data_with_date.drop(columns=[\"trxdate\"])\n",
    "train_data_april = train_data_with_date.drop(columns=[\"trxdate\"])\n",
    " \n",
    "# Separate features and target variable\n",
    "X = train_data_april.drop(columns=[\"Churn\"])\n",
    "y = train_data_april[\"Churn\"]\n",
    " \n",
    "# Function to create different scenarios and evaluate model\n",
    "def evaluate_model_for_ratios(churn_ratio):\n",
    "    churn_data = train_data_april[train_data_april[\"Churn\"] == 1]\n",
    "    non_churn_data = train_data_april[train_data_april[\"Churn\"] == 0]\n",
    " \n",
    "    # Number of non-churn samples to match the desired ratio\n",
    "    non_churn_sample_size = int(len(churn_data) * (1 - churn_ratio) / churn_ratio)\n",
    " \n",
    "    if non_churn_sample_size > len(non_churn_data):\n",
    "        non_churn_sample_size = len(non_churn_data)\n",
    " \n",
    "    non_churn_sample = non_churn_data.sample(non_churn_sample_size, random_state=42)\n",
    " \n",
    "    # Combine churn and non-churn data\n",
    "    balanced_data = pd.concat([churn_data, non_churn_sample])\n",
    "    X_balanced = balanced_data.drop(columns=[\"Churn\"])\n",
    "    y_balanced = balanced_data[\"Churn\"]\n",
    " \n",
    "    # Split data into training and validation sets\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X_balanced, y_balanced, test_size=0.3, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    " \n",
    "    # Train Logistic Regression model\n",
    "    model_lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    model_lr.fit(X_train, y_train)\n",
    " \n",
    "    # Evaluate model on validation set\n",
    "    y_val_pred = model_lr.predict(X_val)\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    val_precision = precision_score(y_val, y_val_pred)\n",
    "    val_recall = recall_score(y_val, y_val_pred)\n",
    "    val_f1 = f1_score(y_val, y_val_pred)\n",
    " \n",
    "    # Evaluate model on test set\n",
    "    y_test_pred = model_lr.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    test_precision = precision_score(y_test, y_test_pred)\n",
    "    test_recall = recall_score(y_test, y_test_pred)\n",
    "    test_f1 = f1_score(y_test, y_test_pred)\n",
    " \n",
    "    print(f\"Churn Ratio: {churn_ratio * 100}%\")\n",
    "    print(\"Validation Metrics:\")\n",
    "    print(\"Accuracy:\", val_accuracy)\n",
    "    print(\"Precision:\", val_precision)\n",
    "    print(\"Recall:\", val_recall)\n",
    "    print(\"F1 Score:\", val_f1)\n",
    "    print()\n",
    "    print(\"Test Metrics:\")\n",
    "    print(\"Accuracy:\", test_accuracy)\n",
    "    print(\"Precision:\", test_precision)\n",
    "    print(\"Recall:\", test_recall)\n",
    "    print(\"F1 Score:\", test_f1)\n",
    "    print()\n",
    " \n",
    "    # Predict and evaluate on April 2024 data\n",
    "    test_data_april_without_churn = test_data_april.drop(columns=[\"Churn\"])\n",
    "    april_prediction = model_lr.predict(test_data_april_without_churn)\n",
    "    april_prediction_proba = model_lr.predict_proba(test_data_april_without_churn)[:, 1]\n",
    " \n",
    "    comparison_df = pd.DataFrame({\n",
    "        \"Customer_id\": test_data_april[\"Customer_id\"],\n",
    "        \"True_Churn\": test_data_april[\"Churn\"],\n",
    "        \"Predicted_Churn\": april_prediction,\n",
    "        \"Predicted_Churn_Probability\": april_prediction_proba\n",
    "    })\n",
    " \n",
    "    print(\"Classification Report for April 2024:\")\n",
    "    print(classification_report(test_data_april[\"Churn\"], april_prediction))\n",
    "    print(\"Confusion Matrix for April 2024:\")\n",
    "    print(confusion_matrix(test_data_april[\"Churn\"], april_prediction))\n",
    "    print()\n",
    " \n",
    "# Evaluate for different churn ratios\n",
    "ratios = [0.5, 0.4, 0.3, 0.2]\n",
    "for ratio in ratios:\n",
    "    evaluate_model_for_ratios(ratio)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
